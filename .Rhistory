vals$run_analysis_flag <- Sys.time()
} else {
shiny::showNotification("Data imported. Digitize the image to continue.", type="warning")
}
}, error=function(e) { shiny::removeNotification(id=id_import); shiny::showNotification(e$message, type="error") })
})
output$hot_risk_table <- rhandsontable::renderRHandsontable({ shiny::req(vals$risk_table_editable); rhandsontable::rhandsontable(vals$risk_table_editable, stretchH="all", height=450) %>% rhandsontable::hot_context_menu(allowRowEdit=TRUE, allowColEdit=FALSE) })
output$hot_y_axis <- rhandsontable::renderRHandsontable({ shiny::req(vals$y_axis_editable); rhandsontable::rhandsontable(vals$y_axis_editable, stretchH="all", height=150) })
# ==============================================================================
# SWITCH ARMS BUTTON
# ==============================================================================
shiny::observeEvent(input$switch_arms, {
shiny::req(vals$risk_table_editable)
temp <- vals$risk_table_editable$N_Risk_G1
vals$risk_table_editable$N_Risk_G1 <- vals$risk_table_editable$N_Risk_G2
vals$risk_table_editable$N_Risk_G2 <- temp
if(!is.null(vals$curve_mapping)) {
temp_map <- vals$curve_mapping$curve_to_G1
vals$curve_mapping$curve_to_G1 <- vals$curve_mapping$curve_to_G2
vals$curve_mapping$curve_to_G2 <- temp_map
}
if(!is.null(vals$final_ipd)) {
vals$run_analysis_flag <- Sys.time()
}
shiny::showNotification("Arms switched. G1 <-> G2", type="warning", duration=4)
})
# ==============================================================================
# CORE ANALYSIS
# ==============================================================================
run_core_analysis <- function() {
Time <- N_Risk_G1 <- time_tick <- nrisk <- N_Risk_G2 <- survival <- NULL
shiny::req(vals$risk_table_editable, vals$y_axis_editable)
# UX FIX: persistent notification until finished
id_cal <- shiny::showNotification("Calculating Metrics... Please wait.", type="message", duration=NULL)
tryCatch({
if(is.null(vals$manual_raw_data)) stop("Missing curve data.")
rt <- vals$risk_table_editable; vy <- vals$y_axis_editable$Y_Values
if(is.null(vals$curve_mapping)) {
vals$curve_mapping <- map_curves_to_risk_groups(vals$manual_raw_data, rt)
msg <- sprintf("Auto-mapping: Curve %d -> G1, Curve %d -> G2",
vals$curve_mapping$curve_to_G1, vals$curve_mapping$curve_to_G2)
shiny::showNotification(msg, type="message", duration=5)
}
limpiar <- function(x) as.numeric(gsub("[^0-9.]", "", as.character(x)))
check_mono <- function(x) {
x_clean <- as.numeric(x[!is.na(x)])
if(length(x_clean) < 2) return(TRUE)
if(any(diff(x_clean) > 0)) return(FALSE)
return(TRUE)
}
if(!check_mono(rt$N_Risk_G1)) stop("Error: N_Risk_G1 increases over time.")
if(!check_mono(rt$N_Risk_G2)) stop("Error: N_Risk_G2 increases over time.")
df_c1 <- rt %>% dplyr::transmute(
time_tick = as.numeric(Time),
nrisk = limpiar(N_Risk_G1),
curve = vals$curve_mapping$curve_to_G1
) %>% dplyr::filter(!is.na(time_tick), !is.na(nrisk))
df_c2 <- rt %>% dplyr::transmute(
time_tick = as.numeric(Time),
nrisk = limpiar(N_Risk_G2),
curve = vals$curve_mapping$curve_to_G2
) %>% dplyr::filter(!is.na(time_tick), !is.na(nrisk))
nrisk_all <- dplyr::bind_rows(df_c1, df_c2)
ipd_list <- list()
for (cid in unique(nrisk_all$curve)) {
km <- subset(vals$manual_raw_data, curve == cid)
nr <- subset(nrisk_all, curve == cid)
if (nrow(nr) >= 2 && nrow(km) > 0) {
ipd_rec <- bayescores::reconstruct_ipd(km, nr)$ipd
if(cid == vals$curve_mapping$curve_to_G1) {
ipd_rec$arm <- "Group 1"
} else {
ipd_rec$arm <- "Group 2"
}
ipd_list[[length(ipd_list) + 1]] <- ipd_rec
}
}
if (length(ipd_list) > 0) {
final <- dplyr::bind_rows(ipd_list)
mod_init <- coxph(Surv(time, status) ~ arm, final)
hr_init <- exp(coef(mod_init)[1])
if(!is.na(hr_init) && hr_init > 1) {
final$arm <- ifelse(final$arm == "Group 1", "Group 2", "Group 1")
temp_map <- vals$curve_mapping$curve_to_G1
vals$curve_mapping$curve_to_G1 <- vals$curve_mapping$curve_to_G2
vals$curve_mapping$curve_to_G2 <- temp_map
temp_risk <- vals$risk_table_editable$N_Risk_G1
vals$risk_table_editable$N_Risk_G1 <- vals$risk_table_editable$N_Risk_G2
vals$risk_table_editable$N_Risk_G2 <- temp_risk
mod_init <- coxph(Surv(time, status) ~ arm, final)
shiny::showNotification("HR > 1 detected. Arms swapped automatically.", type="warning", duration=6)
}
vals$final_ipd <- final
vals$fit_obj <- survfit(Surv(time, status) ~ arm, final)
vals$cox_obj <- mod_init
} else {
stop("Could not reconstruct curves.")
}
data <- vals$final_ipd; arms <- levels(factor(data$arm)); ac <- arms[1]; ae <- arms[2]
mt1 <- max(data$time[data$arm==ac]); mt2 <- max(data$time[data$arm==ae]); tau <- min(mt1, mt2)
n_ctrl <- sum(data$arm==ac); n_exp <- sum(data$arm==ae)
ev_ctrl <- sum(data$status[data$arm==ac]); ev_exp <- sum(data$status[data$arm==ae])
cens_ctrl <- n_ctrl - ev_ctrl; cens_exp <- n_exp - ev_exp
sf <- median(data$time); data$ts <- data$time/sf
fc <- flexsurvcure(Surv(ts, status)~arm, data=data, anc=list(scale=~arm), dist="weibull", link="logistic", mixture=TRUE)
vals$cure_model_obj <- fc
# Calc Reverse KM
rev_km <- survfit(Surv(time, 1-status) ~ 1, data=data)
median_follow_up <- summary(rev_km)$table["median"]
if(is.na(median_follow_up)) median_follow_up <- max(data$time) # Fallback if undefined
# Calc Control Median Survival
km_ctrl <- survfit(Surv(time, status) ~ 1, data=data[data$arm==ac,])
median_surv_ctrl <- summary(km_ctrl)$table["median"]
if(is.na(median_surv_ctrl)) median_surv_ctrl <- max(data$time[data$arm==ac]) # Fallback
maturity_idx <- median_follow_up / median_surv_ctrl
fc_aic <- tryCatch({
flexsurvcure(Surv(time, status)~arm, data=data, anc=list(scale=~arm), dist="weibull", link="logistic", mixture=TRUE)
}, error = function(e) NULL)
res <- fc$res.t
rn <- rownames(res)
theta_logit <- res["theta", 1]
p_theta <- c(plogis(res["theta", 1]), plogis(res["theta", 2]), plogis(res["theta", 3]), res["theta", 4], NA_real_)
p_shape <- c(exp(res["shape", 1]), exp(res["shape", 2]), exp(res["shape", 3]), res["shape", 4], exp(res["shape", 1]))
p_scale <- c(exp(res["scale", 1]), exp(res["scale", 2]), exp(res["scale", 3]), res["scale", 4], exp(res["scale", 1]))
arm_row <- rn[!rn %in% c("theta", "shape", "scale") & !grepl("^scale\\(", rn)]
if(length(arm_row) > 0) {
p_arm <- c(res[arm_row[1], 1], res[arm_row[1], 2], res[arm_row[1], 3], res[arm_row[1], 4], exp(res[arm_row[1], 1]))
} else {
p_arm <- rep(NA, 5)
}
scale_arm_row <- rn[grepl("^scale\\(", rn)]
if(length(scale_arm_row) > 0) {
p_sc_arm <- c(res[scale_arm_row[1], 1], res[scale_arm_row[1], 2], res[scale_arm_row[1], 3], res[scale_arm_row[1], 4], exp(res[scale_arm_row[1], 1]))
} else {
p_sc_arm <- rep(NA, 5)
}
# Pearson from Vcov
vc <- vcov(fc)
ith <- grep("arm", rownames(vc)); isc <- grep("scale\\(arm", rownames(vc))
idx1 <- ith[!ith %in% isc]; idx2 <- isc
pearson <- NA
if(length(idx1)>0 && length(idx2)>0) {
cv <- vc[idx1[1], idx2[1]]; v1 <- vc[idx1[1], idx1[1]]; v2 <- vc[idx2[1], idx2[1]]
if(!is.na(v1) && !is.na(v2) && v1>0 && v2>0) pearson <- cv/(sqrt(v1)*sqrt(v2))
}
# Parametric Bootstrap for Spearman/Kendall
spearman <- NA; kendall <- NA
tryCatch({
if(length(idx1)>0 && length(idx2)>0) {
mu_vec <- coef(fc)[c(idx1[1], idx2[1])]
sigma_mat <- vc[c(idx1[1], idx2[1]), c(idx1[1], idx2[1])]
# Simulate using Cholesky to avoid extra dependencies if possible
n_sim <- 1000
L <- chol(sigma_mat)
Z <- matrix(stats::rnorm(n_sim * 2), n_sim, 2)
sim_draws <- Z %*% L + matrix(rep(mu_vec, each=n_sim), nrow=n_sim)
spearman <- cor(sim_draws[,1], sim_draws[,2], method="spearman")
kendall <- cor(sim_draws[,1], sim_draws[,2], method="kendall")
}
}, error=function(e) NULL)
rate_c <- p_theta[1]
rate_e <- if(!is.na(theta_logit) && !is.na(p_arm[1])) plogis(theta_logit + p_arm[1]) else NA
mae_cure <- NA
tryCatch({
arms_levels <- levels(factor(data$arm))
arm_vals <- c(arms_levels[1], arms_levels[2])
times_grid <- sort(unique(c(0, seq(0, tau, length.out = 101), tau)))
times_grid <- times_grid[times_grid >= 0]
km_fit <- survfit(Surv(time, status) ~ arm, data = data)
s_km <- summary(km_fit, times = times_grid, extend = TRUE)
KM_S <- matrix(NA, nrow = length(times_grid), ncol = 2)
for(k in seq_along(times_grid)) {
idx1 <- which(s_km$time == times_grid[k] & s_km$strata == paste0("arm=", arm_vals[1]))
idx2 <- which(s_km$time == times_grid[k] & s_km$strata == paste0("arm=", arm_vals[2]))
if(length(idx1) > 0) KM_S[k, 1] <- s_km$surv[idx1[1]]
if(length(idx2) > 0) KM_S[k, 2] <- s_km$surv[idx2[1]]
}
KM_S[is.na(KM_S)] <- 1
if(!is.null(fc_aic)) {
CURE_S <- cbind(
summary(fc_aic, newdata = data.frame(arm = arm_vals[1]), type = "survival", t = times_grid)[[1]]$est,
summary(fc_aic, newdata = data.frame(arm = arm_vals[2]), type = "survival", t = times_grid)[[1]]$est
)
} else {
CURE_S <- matrix(NA, nrow = length(times_grid), ncol = 2)
}
mae_cure <- mean(abs(CURE_S - KM_S), na.rm = TRUE)
vals$calib_data <- list(
times = times_grid,
km_fit = km_fit,
KM_S = KM_S,
CURE_S = CURE_S,
tau = tau,
arm_vals = arm_vals
)
}, error = function(e) {
mae_cure <<- NA
})
fr <- data.frame(
N_Total = nrow(data), N_Ctrl = n_ctrl, N_Exp = n_exp,
Events_Total = sum(data$status), Events_Ctrl = ev_ctrl, Events_Exp = ev_exp,
Censored_Total = nrow(data)-sum(data$status), Censored_Ctrl = cens_ctrl, Censored_Exp = cens_exp,
Censoring_Rate_Global = 1-mean(data$status), Censoring_Rate_Ctrl = cens_ctrl/n_ctrl, Censoring_Rate_Exp = cens_exp/n_exp,
Tau_Common = tau,
Pearson_Correlation = pearson,
Spearman_Correlation = spearman,
Kendall_Correlation = kendall,
Maturity_Index = maturity_idx,
Median_FollowUp = median_follow_up,
Median_Surv_Ctrl = median_surv_ctrl
)
vals$analysis_results_full <- fr
# --- PREPARE SUMMARY TABLE (REPLACING CURE MODEL COLS WITH CORRELATION/MATURITY) ---
vals_vec <- sapply(fr, function(x) {
if(is.numeric(x)) as.character(round(x, 4)) else as.character(x)
})
# Block 1: Sample Info
b1_m <- c("N_Total", "N_Ctrl", "N_Exp", "Tau_Common")
b1_v <- vals_vec[b1_m]
# Block 2: Events
b2_m <- c("Events_Total", "Censored_Total", "Censoring_Rate_Global", "Events_Ctrl")
b2_v <- vals_vec[b2_m]
# Block 3: Instability Metrics (Updated with correlations and medians)
b3_m <- c("Pearson_Correlation", "Spearman_Correlation", "Kendall_Correlation",
"Maturity_Index", "Median_FollowUp", "Median_Surv_Ctrl")
b3_v <- vals_vec[b3_m]
# Pad to ensure same length
len <- max(length(b1_m), length(b2_m), length(b3_m))
pad <- function(x, l) c(x, rep("", l-length(x)))
df_view <- data.frame(
Metric_1 = pad(names(b1_v), len), Value_1 = pad(unname(b1_v), len),
Metric_2 = pad(names(b2_v), len), Value_2 = pad(unname(b2_v), len),
Metric_3 = pad(names(b3_v), len), Value_3 = pad(unname(b3_v), len)
)
colnames(df_view) <- c("Sample Info", "Value", "Events", "Value", "Instability Metrics", "Value")
vals$analysis_summary_view <- df_view
# --- GENERATE INTERPRETATION HTML ---
m_val <- maturity_idx
rho_val <- abs(pearson)
if(is.na(rho_val)) rho_val <- 0
# --- PLATEAU VISUAL CHECK (15% TAIL DROP) ---
# Logic: Check drop from 0.85*tau to tau.
plateau_visual_stable <- TRUE
tryCatch({
km_check <- vals$calib_data$km_fit
t_start_check <- 0.85 * tau
s_start <- summary(km_check, times = t_start_check)$surv
s_end <- summary(km_check, times = tau)$surv
# If mean survival drops more than 0.05 in the last 15% of the curve -> Unstable
if(mean(s_start) - mean(s_end) > 0.05) plateau_visual_stable <- FALSE
}, error=function(e) NULL)
interp_status <- ""
interp_rec <- ""
model_suggestion <- ""
if(m_val < 2.0) {
if(rho_val < 0.4) {
interp_status <- "Artifactual Stability (High False Positive Risk)"
interp_rec <- "Suggestion: Data presents characteristics of artifactual stability. Low correlation in immature data may be misleading. It is recommended to apply a Skeptical Prior on the OR to weight the analysis towards an AFT model interpretation if evidence is weak."
if(!plateau_visual_stable) model_suggestion <- "Consider setting 'Cure Belief' to 'unlikely' (AFT model)."
} else if(rho_val >= 0.7) {
interp_status <- "Structural Uncertainty"
interp_rec <- "Suggestion: The model reflects uncertainty in separating Cure from Delay (high correlation). This 'Structural Uncertainty' is expected. Trust the uncertainty and consider reporting the Time Ratio (TR)."
model_suggestion <- "Consider setting 'Cure Belief' to 'unlikely' (AFT model)."
} else {
interp_status <- "Ambiguous Immature"
interp_rec <- "Suggestion: Data is immature and model stability is inconclusive. Interpret with caution."
if(!plateau_visual_stable) model_suggestion <- "Consider setting 'Cure Belief' to 'unlikely' (AFT model)."
}
} else {
if(rho_val < 0.4) {
interp_status <- "Confirmed Cure"
interp_rec <- "Suggestion: Valid Benefit. The plateau appears structurally identified. Reporting the Cure OR is supported by the data."
} else {
interp_status <- "Weak Signal / Dilution"
interp_rec <- "Suggestion: Inconclusive or Negative. There is likely no true cure signal; the model may be struggling to fit noise."
}
}
# If specific criteria met, force suggestion
if(m_val < 2.0 || rho_val >= 0.7 || !plateau_visual_stable) {
model_suggestion <- "<b>Modeling Strategy Suggestion:</b> Data lacks sufficient stability for a flexible cure model (due to Immaturity, Ambiguity, or lack of visual plateau). <br>Consider setting 'Cure Belief' to <b>'unlikely'</b> (which converts the model to an AFT approach) to reduce overfitting."
}
html_content <- paste0(
"<h5>Interpretation Suggestions</h5>",
"<p><b>Analysis Criteria Used:</b></p>",
"<ul>",
"<li><b>Maturity Index (M):</b> Calculated as Median Follow-up / Control Median Survival. (Values < 2.0 suggest immaturity).</li>",
"<li><b>Parametric Instability (rho):</b> Pearson correlation between Log(OR) and Log(TR). (Values > 0.7 suggest instability).</li>",
"<li><b>Plateau Stability:</b> Checked from Tau (", round(tau,1), ") backwards to ", round(0.85*tau,1), ".</li>",
"</ul>",
"<p><b>Computed Values:</b> M = ", round(m_val, 2), ", rho = ", round(rho_val, 2), ".</p>",
"<hr>",
"<p><b>Diagnosis:</b> ", interp_status, "</p>",
"<p><b>Recommendation:</b> ", interp_rec, "</p>",
if(model_suggestion != "") paste0("<hr><p style='color: #E65100;'>", model_suggestion, "</p>") else ""
)
vals$interpretation_html <- shiny::HTML(html_content)
shiny::removeNotification(id=id_cal)
shiny::showNotification("Analysis Complete.", type="message")
}, error = function(e) { shiny::removeNotification(id=id_cal); shiny::showNotification(paste("Error:", e$message), type="error") })
}
output$forensic_interpretation_ui <- shiny::renderUI({
shiny::req(vals$interpretation_html)
vals$interpretation_html
})
shiny::observeEvent(input$apply_edits, {
vals$risk_table_editable <- rhandsontable::hot_to_r(input$hot_risk_table)
vals$y_axis_editable <- rhandsontable::hot_to_r(input$hot_y_axis)
run_core_analysis()
})
shiny::observeEvent(vals$run_analysis_flag, { run_core_analysis() }, ignoreInit = TRUE)
# ==============================================================================
# BAYESIAN MODEL
# ==============================================================================
shiny::observeEvent(input$run_model, {
shiny::req(vals$final_ipd)
# UX FIX: Persistent notification
id_mod <- shiny::showNotification("Compiling and fitting model... This may take several minutes.", type = "message", duration = NULL)
tryCatch({
hist_arg <- if (input$use_historical) {
paste0("TRUE, params=c(", input$hist_mean, ",", input$hist_sd, ")")
} else {
paste0("FALSE, belief='", input$cure_belief, "'")
}
vals$code_text <- paste0(
"library(bayescores)\nlibrary(rstan)\nipd <- readRDS('path/to/ipd.rds')\n",
"fit <- fit_bayesian_cure_model(ipd, time_col='time', event_col='status', arm_col='arm', iter=",
input$iter, ", chains=", input$chains, ", warmup=", input$warmup, ", shared_shape=",
input$shared_shape, ", use_historical_prior=", hist_arg, ")\n",
"diagnose_fit(fit$stan_fit)\nmodel_diagnostics(fit)\n",
"# Plots\n",
"bayescores::plot_densities(fit)\n",
"bayescores::plot_correlated_densities(fit)"
)
vals$model_fit_obj <- bayescores::fit_bayesian_cure_model(
vals$final_ipd,
time_col = "time", event_col = "status", arm_col = "arm",
iter = input$iter, chains = input$chains, warmup = input$warmup,
seed = seed_val, adapt_delta = adapt_delta_val,
shared_shape = input$shared_shape,
use_historical_prior = input$use_historical,
historical_prior_params = c(input$hist_mean, input$hist_sd),
cure_belief = input$cure_belief
)
shiny::removeNotification(id = id_mod)
shiny::showNotification("Model fitted!", type = "message")
}, error = function(e) {
shiny::removeNotification(id = id_mod)
shiny::showNotification(paste("Error:", e$message), type = "error", duration = 10)
})
})
output$model_summary <- shiny::renderPrint({
shiny::req(vals$model_fit_obj)
# FIX: Use correct argument based on user feedback
if (exists("outcomes", asNamespace("bayescores"))) {
bayescores::outcomes(vals$model_fit_obj, correlation_method = "pearson")
} else {
print(vals$model_fit_obj)
}
})
output$plot_densities <- shiny::renderPlot({
shiny::req(vals$model_fit_obj)
p <- bayescores::plot_densities(vals$model_fit_obj)
print(p + ggplot2::theme(aspect.ratio = 1))
})
output$plot_correlated <- shiny::renderPlot({
shiny::req(vals$model_fit_obj)
bayescores::plot_correlated_densities(vals$model_fit_obj) + ggplot2::theme(aspect.ratio = 1)
})
output$plot_model_fit <- shiny::renderPlot({
shiny::req(vals$model_fit_obj)
graphics::par(pty = "s")
plot(vals$model_fit_obj)
})
output$text_diagnostics_table <- shiny::renderPrint({
shiny::req(vals$model_fit_obj)
tryCatch({
if (exists("diagnose_fit", asNamespace("bayescores"))) {
print(bayescores::diagnose_fit(vals$model_fit_obj$stan_fit))
} else {
print(rstan::monitor(vals$model_fit_obj$stan_fit, print = FALSE))
}
}, error = function(e) {
print(rstan::check_hmc_diagnostics(vals$model_fit_obj$stan_fit))
})
})
output$plot_diagnostics <- shiny::renderPlot({
shiny::req(vals$model_fit_obj)
tryCatch({
bayescores::model_diagnostics(vals$model_fit_obj)
}, error = function(e) {
plot(vals$model_fit_obj$stan_fit, pars = c("lp__"))
})
})
output$repro_code <- shiny::renderText({
shiny::req(vals$code_text)
vals$code_text
})
output$dl_model_rds <- shiny::downloadHandler(
filename = function() "bayesian_model.rds",
content = function(f) saveRDS(vals$model_fit_obj, f)
)
# CSV Download logic
draws_csv_logic <- function(f) {
shiny::req(vals$model_fit_obj)
draws <- as.data.frame(vals$model_fit_obj$stan_fit)
write.csv(draws, f, row.names = FALSE)
}
output$dl_draws_csv <- shiny::downloadHandler(filename = "mcmc_draws.csv", content = draws_csv_logic)
output$dl_plot_dens <- shiny::downloadHandler(
filename = "densities.pdf",
content = function(f) {
pdf(f, width = 10, height = 8, onefile=FALSE)
p <- bayescores::plot_densities(vals$model_fit_obj)
print(p + ggplot2::theme(aspect.ratio = 1))
dev.off()
}
)
output$dl_plot_corr <- shiny::downloadHandler(
filename = "correlated.pdf",
content = function(f) {
pdf(f, width = 10, height = 8)
print(bayescores::plot_correlated_densities(vals$model_fit_obj) + ggplot2::theme(aspect.ratio = 1))
dev.off()
}
)
output$dl_plot_fit <- shiny::downloadHandler(
filename = "fit.pdf",
content = function(f) {
pdf(f, width = 10, height = 8)
graphics::par(pty = "s")
plot(vals$model_fit_obj)
dev.off()
}
)
# Updated: Download PLOT in Diagnostics tab - FIX to ensure PDF generation works
output$dl_plot_diag <- shiny::downloadHandler(
filename = "diagnostics.pdf",
content = function(f) {
shiny::req(vals$model_fit_obj)
pdf(f, width = 10, height = 8)
tryCatch({
p_diag <- bayescores::model_diagnostics(vals$model_fit_obj)
# Check if result is a ggplot/gtable object and explicitly print it
if(!is.null(p_diag) && (inherits(p_diag, "ggplot") || inherits(p_diag, "gtable"))) {
print(p_diag)
}
}, error = function(e) {
# Fallback
plot(vals$model_fit_obj$stan_fit, pars = c("lp__"))
})
dev.off()
}
)
# ==============================================================================
# ORIGINAL OUTPUTS
# ==============================================================================
output$metrics_summary_table <- shiny::renderTable({ shiny::req(vals$analysis_summary_view); vals$analysis_summary_view }, striped=TRUE, bordered=TRUE)
output$survfit_output <- shiny::renderPrint({
shiny::req(vals$fit_obj)
cat("--- SURVFIT (KAPLAN-MEIER) ---\n\n")
print(vals$fit_obj)
if(!is.null(vals$cox_obj)) {
cat("\n\n--- COX MODEL SUMMARY ---\n")
print(summary(vals$cox_obj))
}
})
output$cure_surv_output <- shiny::renderPrint({ shiny::req(vals$cure_model_obj); print(vals$cure_model_obj); cat("\nPEARSON CORRELATION:", vals$analysis_results_full$Pearson_Correlation) })
output$calib_plot_output <- shiny::renderPlot({
shiny::req(vals$calib_data)
cd <- vals$calib_data
par(mfrow = c(1, 2), mar = c(4, 4, 3, 1))
plot(cd$km_fit, conf.int = FALSE, lwd = 2, col = c("black", "gray60"),
xlab = "Time", ylab = "S(t)", xlim = c(0, cd$tau),
main = paste0("Control (tau=", round(cd$tau, 1), ")"))
lines(cd$times, cd$CURE_S[,1], lty = 3, lwd = 2, col = "red")
legend("topright", legend = c("KM", "Cure"),
lty = c(1, 3), lwd = 2, col = c("black", "red"), bty = "n", cex = 0.9)
plot(cd$km_fit, conf.int = FALSE, lwd = 2, col = c("gray60", "black"),
xlab = "Time", ylab = "S(t)", xlim = c(0, cd$tau),
main = paste0("Experimental (tau=", round(cd$tau, 1), ")"))
lines(cd$times, cd$CURE_S[,2], lty = 3, lwd = 2, col = "red")
legend("topright", legend = c("KM", "Cure"),
lty = c(1, 3), lwd = 2, col = c("black", "red"), bty = "n", cex = 0.9)
})
output$original_image_output <- shiny::renderImage({
if(vals$mode=="manual" && !is.null(vals$processed_img_path))
list(src=vals$processed_img_path, height="100%")
else
list(src="", alt="")
}, deleteFile=FALSE)
output$km_plot_output <- shiny::renderPlot({
if(!is.null(vals$fit_obj)) {
survminer::ggsurvplot(vals$fit_obj, data=vals$final_ipd, pval=TRUE, risk.table=TRUE, risk.table.height=0.25)
} else if(!is.null(vals$manual_raw_data)) {
ggplot(vals$manual_raw_data, aes(x=time, y=survival, col=factor(curve))) +
geom_step() +
labs(title="Digitized Curves (Pre-Analysis)",
subtitle=if(!is.null(vals$curve_mapping)) sprintf("Curve %d -> G1 (Exp), Curve %d -> G2 (Ctrl)",
vals$curve_mapping$curve_to_G1,
vals$curve_mapping$curve_to_G2) else NULL)
}
})
output$dl_ipd_excel <- shiny::downloadHandler(
filename="ipd.xlsx",
content=function(f) writexl::write_xlsx(vals$final_ipd, f)
)
}
return(shiny::shinyApp(ui, server))
}
source("~/aft cure model/bystools/R/km2bayes.R")
km2bayes()
system("git push")
